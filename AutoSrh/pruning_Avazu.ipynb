{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefa3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import wandb\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from data.dataset import get_cf_dataset,get_ctr_dataset,CTR_Dataset,get_avazu_dataset,Avazu_Dataset\n",
    "from utils import seed_everything\n",
    "from model.nas import Dnis, AdamNas, FM\n",
    "from shutil import copyfile\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aac0bbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data_path\", type=str, default='data/avazu/click.pickle')\n",
    "parser.add_argument(\"--exp\", type=str, default='nas 31')\n",
    "parser.add_argument(\"--cuda\", nargs='*', type=int, default=[3], help='cuda visible devices')\n",
    "parser.add_argument(\"--embedding_dim\", type=int, default=64)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=4096)\n",
    "parser.add_argument(\"--lr_w\", type=float, default=1e-2)\n",
    "parser.add_argument(\"--lr_a\", type=float, default=1e-2)\n",
    "parser.add_argument(\"--num_epochs\", type=int, default=100)\n",
    "parser.add_argument(\"--init_alpha\", type=float, default=1)\n",
    "parser.add_argument(\"--alpha_optim\", type=str, default='SGD')\n",
    "parser.add_argument(\"--load_checkpoint\", type=int, default=1)\n",
    "parser.add_argument(\"--warm_start\", type=int, default=0)\n",
    "parser.add_argument(\"--num_dim_split\", type=int, default=64)\n",
    "parser.add_argument(\"--search_space\", type=str, default='free')\n",
    "parser.add_argument(\"--l1\", type=float, default=0)\n",
    "parser.add_argument(\"--normalize\", type=int, default=0)\n",
    "parser.add_argument(\"--use_second_grad\", type=int, default=1)\n",
    "#parser.add_argument(\"--model_name\", type=str, default='Wide_and_Deep')\n",
    "parser.add_argument(\"--model_name\", type=str, default='DeepFM')\n",
    "parser.add_argument(\"--alpha_upper_round\", type=int, default=0)\n",
    "parser.add_argument(\"--dataset_type\", type=str, default='ava')\n",
    "args = parser.parse_args(\"\".split())\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = f'{args.cuda}'[1:-1]\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "463e104d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has been processed. Reading the cache...\n"
     ]
    }
   ],
   "source": [
    "train_dataset, val_dataset, test_dataset, num_features = get_avazu_dataset(args.data_path)\n",
    "num_fields = 23   \n",
    "batch_size = args.batch_size\n",
    "val_dataloader = DataLoader(val_dataset, batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size, shuffle=False, num_workers=8, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2091906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dnis.feature_nums:tensor([154448, 308897, 308897, 308897, 463350])\n"
     ]
    }
   ],
   "source": [
    "#dnis = Dnis(num_features, args.embedding_dim, num_dim_split=args.num_dim_split, search_space=args.search_space,normalize=args.normalize, model_name=args.model_name,num_fields=num_fields, feature_split=[0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1])\n",
    "dnis = Dnis(num_features, args.embedding_dim, num_dim_split=args.num_dim_split, search_space=args.search_space,\n",
    "                normalize=args.normalize, model_name=args.model_name,num_fields=num_fields, feature_split=[0.1,0.2,0.2,0.2,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4440813f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dnis.load_state_dict(torch.load(\"wandb/run-20210720_122759-3i1ozpwr/files/DNIS-CTR-Avazu.tar\"))\n",
    "dnis.load_state_dict(torch.load(\"wandb/run-20210716_184325-3qsykpim/files/DNIS-CTR-Avazu.tar\"))\n",
    "#dnis.load_state_dict(torch.load(\"wandb/run-20210728_125107-sfshogmi/files/DNIS-CTR-Avazu.tar\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42d5a86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dnis(\n",
       "  (feature_embeddings): Embedding(1544489, 64)\n",
       "  (model): DeepFM(\n",
       "    (feature_biases): Embedding(1544489, 1)\n",
       "    (fc1): Linear(in_features=1472, out_features=400, bias=True)\n",
       "    (fc2): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (fc3): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (fc4): Linear(in_features=400, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnis.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07a75a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha Parameter containing:\n",
      "tensor([[8.9068e-01, 7.4982e-01, 6.5229e-02, 2.8706e-01, 4.5175e-01, 3.8904e-02,\n",
      "         6.0947e-02, 9.4172e-01, 1.1652e-01, 1.3816e-01, 1.0624e-01, 4.5850e-01,\n",
      "         4.4884e-01, 7.0286e-01, 8.5268e-02, 2.9903e-01, 1.0281e-01, 1.5134e-01,\n",
      "         1.5441e-01, 5.2884e-02, 7.3251e-02, 3.7504e-01, 6.9772e-02, 1.7425e-01,\n",
      "         7.6491e-01, 1.4102e-01, 5.4107e-01, 4.8125e-02, 1.2655e-01, 1.0688e-01,\n",
      "         4.5544e-02, 3.7616e-01, 4.8382e-01, 7.0013e-01, 5.8183e-02, 4.5206e-03,\n",
      "         7.8600e-02, 1.0800e-01, 5.4182e-01, 6.2045e-01, 5.4111e-02, 1.3194e-01,\n",
      "         3.8040e-01, 3.9374e-02, 4.1311e-03, 4.2428e-01, 0.0000e+00, 1.0000e+00,\n",
      "         2.9202e-01, 1.1475e-01, 4.7421e-01, 8.5632e-01, 6.2379e-01, 1.5601e-01,\n",
      "         3.6184e-01, 1.8883e-01, 3.6037e-02, 4.6095e-01, 2.8671e-01, 2.5716e-02,\n",
      "         6.1751e-01, 3.1376e-01, 3.8785e-02, 1.2487e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0466e-02, 3.8053e-03, 4.8646e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7962e-03, 0.0000e+00,\n",
      "         1.7456e-03, 1.1921e-03, 1.2764e-02, 0.0000e+00, 0.0000e+00, 3.9439e-02,\n",
      "         1.9016e-02, 0.0000e+00, 2.1656e-03, 8.9960e-03, 0.0000e+00, 1.8675e-02,\n",
      "         1.6556e-02, 1.0185e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.1943e-03, 4.9236e-03, 5.8158e-03, 0.0000e+00, 2.4732e-02, 0.0000e+00,\n",
      "         7.0980e-03, 0.0000e+00, 1.6308e-02, 0.0000e+00, 1.1993e-02, 0.0000e+00,\n",
      "         3.0525e-03, 4.1716e-03, 1.1671e-02, 0.0000e+00, 0.0000e+00, 1.6625e-02,\n",
      "         0.0000e+00, 8.1553e-05, 4.1380e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.1874e-03, 0.0000e+00, 6.9782e-04, 6.7532e-03, 0.0000e+00, 1.2081e-02,\n",
      "         0.0000e+00, 2.9366e-03, 6.4828e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 7.2035e-03, 0.0000e+00, 1.0301e-02, 1.6835e-03,\n",
      "         2.4703e-03, 0.0000e+00, 0.0000e+00, 1.5935e-02, 6.1639e-03, 2.4575e-02,\n",
      "         0.0000e+00, 0.0000e+00, 2.0380e-02, 0.0000e+00, 5.9168e-03, 1.8990e-02,\n",
      "         0.0000e+00, 4.0948e-02, 1.6606e-02, 5.0269e-03, 3.9387e-03, 0.0000e+00,\n",
      "         0.0000e+00, 1.3623e-02, 1.1564e-02, 1.2298e-03, 9.5475e-03, 6.4048e-03,\n",
      "         9.1596e-03, 0.0000e+00, 1.3643e-02, 0.0000e+00, 1.4355e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5290e-02, 0.0000e+00, 1.3582e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 9.9261e-03, 0.0000e+00, 4.1403e-04, 1.8210e-02,\n",
      "         3.3149e-03, 0.0000e+00, 3.1715e-02, 4.4614e-03, 5.3758e-03, 0.0000e+00,\n",
      "         3.3330e-03, 5.0900e-03, 8.3437e-03, 0.0000e+00, 1.2708e-02, 3.1442e-02,\n",
      "         2.5010e-02, 0.0000e+00, 4.8547e-02, 0.0000e+00],\n",
      "        [7.8030e-03, 0.0000e+00, 8.8367e-03, 1.1028e-02, 0.0000e+00, 1.6500e-02,\n",
      "         0.0000e+00, 6.0868e-03, 2.7326e-03, 0.0000e+00, 4.0200e-03, 5.3879e-03,\n",
      "         1.0030e-02, 5.1090e-03, 8.0209e-03, 3.4246e-03, 4.3654e-03, 4.0868e-03,\n",
      "         7.8400e-03, 1.8859e-02, 0.0000e+00, 2.6059e-02, 6.3329e-03, 8.9396e-03,\n",
      "         7.9628e-03, 6.1231e-03, 6.3084e-03, 0.0000e+00, 7.9698e-04, 5.1872e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3300e-03, 0.0000e+00, 2.3333e-03,\n",
      "         0.0000e+00, 1.2482e-02, 0.0000e+00, 1.2749e-03, 0.0000e+00, 7.5244e-03,\n",
      "         0.0000e+00, 4.4921e-03, 6.1712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.6949e-03, 9.8949e-03, 0.0000e+00, 8.0005e-03, 0.0000e+00, 0.0000e+00,\n",
      "         7.3086e-03, 5.8687e-03, 6.7976e-05, 0.0000e+00, 0.0000e+00, 4.9498e-03,\n",
      "         1.1147e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7242e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3328e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5545e-04, 0.0000e+00,\n",
      "         1.9385e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.0741e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3378e-03,\n",
      "         5.9076e-04, 1.0756e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1658e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], requires_grad=True)\n",
      "feature_embeddings.weight Parameter containing:\n",
      "tensor([[ 1.1685e-02,  1.0090e-01,  1.0588e-01,  ...,  6.8006e-01,\n",
      "          1.7277e-01, -5.5160e-01],\n",
      "        [ 1.2717e-01, -2.9075e-02,  6.5321e-03,  ...,  7.4864e-02,\n",
      "          5.3864e-02, -2.5512e-01],\n",
      "        [-3.6245e-01,  5.7768e-01,  9.3803e-02,  ..., -9.2616e-02,\n",
      "         -2.0556e-01, -2.1883e-01],\n",
      "        ...,\n",
      "        [ 5.9820e-04,  2.6121e-04, -8.9212e-04,  ...,  4.4282e-04,\n",
      "         -4.5947e-04, -1.1509e-03],\n",
      "        [ 1.9591e-04, -1.4190e-04,  5.2632e-04,  ...,  1.5511e-04,\n",
      "          7.5685e-04, -5.3025e-04],\n",
      "        [-5.3668e-03, -4.9665e-03,  2.4543e-03,  ...,  8.1259e-03,\n",
      "          4.3659e-03, -8.2888e-03]], requires_grad=True)\n",
      "model.bias Parameter containing:\n",
      "tensor([0.0267], requires_grad=True)\n",
      "model.feature_biases.weight Parameter containing:\n",
      "tensor([[ 0.0549],\n",
      "        [ 0.0384],\n",
      "        [ 0.0327],\n",
      "        ...,\n",
      "        [-0.0004],\n",
      "        [-0.0009],\n",
      "        [-0.0322]], requires_grad=True)\n",
      "model.fc1.weight Parameter containing:\n",
      "tensor([[ 0.0254, -0.0180,  0.0762,  ..., -0.0110,  0.0138,  0.0313],\n",
      "        [-0.0094, -0.0223,  0.0533,  ..., -0.0456,  0.0558, -0.0555],\n",
      "        [ 0.0247, -0.0229,  0.0146,  ...,  0.0274,  0.0265,  0.0692],\n",
      "        ...,\n",
      "        [-0.0225,  0.0871,  0.0008,  ...,  0.1078, -0.0325,  0.0500],\n",
      "        [-0.0020,  0.0013, -0.0722,  ...,  0.1128, -0.0539,  0.0741],\n",
      "        [ 0.0505,  0.0535,  0.0184,  ...,  0.0927, -0.0434,  0.0294]],\n",
      "       requires_grad=True)\n",
      "model.fc1.bias Parameter containing:\n",
      "tensor([-0.0867, -0.0510, -0.0889, -0.1182, -0.1312, -0.1090, -0.0804, -0.0136,\n",
      "        -0.2596, -0.0661, -0.1042, -0.1011, -0.0748, -0.1133, -0.0580, -0.1024,\n",
      "        -0.2658, -0.1929, -0.0816, -0.0636, -0.2082, -0.0983, -0.2445, -0.0306,\n",
      "        -0.0579, -0.2582, -0.1454, -0.0295, -0.1530, -0.1421, -0.0831, -0.1302,\n",
      "        -0.0501,  0.0496, -0.1104, -0.1011, -0.2020, -0.1084, -0.0982, -0.0509,\n",
      "        -0.1085, -0.0567, -0.1056, -0.0618, -0.1336, -0.0406, -0.2130, -0.1949,\n",
      "        -0.1610, -0.1897, -0.1096, -0.2222, -0.1073, -0.0663, -0.0391, -0.2590,\n",
      "        -0.0890, -0.1180, -0.2068, -0.0281, -0.1352, -0.0783, -0.1716, -0.0661,\n",
      "        -0.1173, -0.0347, -0.1116, -0.1290, -0.0825, -0.0699, -0.0609, -0.0661,\n",
      "        -0.2144, -0.1357, -0.1215, -0.0473, -0.2684, -0.0957, -0.0103, -0.1197,\n",
      "        -0.0813, -0.1939, -0.1049, -0.2953, -0.0989, -0.2031, -0.1036, -0.0215,\n",
      "        -0.0613, -0.3704, -0.0963, -0.0398, -0.0565, -0.0408, -0.0637, -0.1302,\n",
      "        -0.0034, -0.0675, -0.1260, -0.1915, -0.1404, -0.1567, -0.0412,  0.0455,\n",
      "        -0.0411, -0.0444, -0.0952, -0.1733, -0.0536, -0.2279, -0.0923, -0.0678,\n",
      "        -0.1020, -0.1740, -0.1365, -0.2307, -0.0947, -0.0964, -0.2365, -0.0963,\n",
      "        -0.2397, -0.0474, -0.0580, -0.0463, -0.0654, -0.2263, -0.1489, -0.1533,\n",
      "        -0.1717, -0.0622, -0.1050, -0.0965, -0.0838, -0.1363, -0.1506, -0.2012,\n",
      "        -0.1353,  0.0152, -0.0375, -0.1737, -0.1615, -0.1866, -0.0949, -0.0515,\n",
      "        -0.1277, -0.0168, -0.1570, -0.0500,  0.0157, -0.2168, -0.0954, -0.1280,\n",
      "        -0.0876, -0.0864, -0.1227,  0.0090, -0.0500, -0.0217, -0.0727, -0.0330,\n",
      "        -0.0536, -0.0723, -0.0386, -0.1208, -0.1943, -0.0845, -0.0862, -0.0578,\n",
      "        -0.2668, -0.0818, -0.0431, -0.0482, -0.0166, -0.0712, -0.0170, -0.0278,\n",
      "        -0.0521, -0.0467, -0.2600, -0.0437, -0.0695, -0.1524, -0.0986, -0.0997,\n",
      "        -0.0300, -0.0639, -0.0760, -0.1543, -0.0523, -0.0409, -0.1841, -0.1088,\n",
      "        -0.0730, -0.0831, -0.2100, -0.0577, -0.1159, -0.1629, -0.0500, -0.1561,\n",
      "        -0.0330, -0.0752, -0.2852, -0.1709, -0.1654, -0.2500, -0.1626,  0.0023,\n",
      "        -0.0197, -0.0922, -0.1530, -0.2171, -0.0344, -0.1185, -0.1914, -0.0684,\n",
      "        -0.0599, -0.0461, -0.1361, -0.2213, -0.0565, -0.1854, -0.0750, -0.1673,\n",
      "        -0.0828, -0.0669, -0.0622, -0.2276, -0.2846, -0.1285, -0.0164, -0.0601,\n",
      "        -0.1783, -0.2584, -0.0311, -0.1196, -0.1352, -0.0483, -0.0526, -0.0850,\n",
      "        -0.0665, -0.0947, -0.2496, -0.0619, -0.2079, -0.0794, -0.2540, -0.0224,\n",
      "        -0.0268, -0.2084, -0.0285, -0.1095, -0.0100, -0.1381, -0.0955, -0.1232,\n",
      "        -0.1944, -0.0690, -0.2401, -0.0605, -0.1614, -0.0859, -0.2933, -0.0631,\n",
      "        -0.0853, -0.2429, -0.0425, -0.1051, -0.0906, -0.1980, -0.0518, -0.1179,\n",
      "        -0.0469, -0.0399, -0.1006, -0.1065, -0.1589, -0.1411, -0.1900, -0.0588,\n",
      "        -0.0117, -0.0898, -0.1134, -0.2360, -0.0950, -0.1352, -0.1686, -0.0894,\n",
      "        -0.0381, -0.0898, -0.0939, -0.0787, -0.2890, -0.1648, -0.0860, -0.1050,\n",
      "        -0.1354, -0.2026, -0.0521, -0.0408, -0.1821, -0.0118, -0.1249, -0.1314,\n",
      "        -0.0620, -0.0625, -0.0455, -0.0454, -0.0802, -0.0997, -0.1777, -0.1324,\n",
      "        -0.0504, -0.1466, -0.0876, -0.0465, -0.2583, -0.2504, -0.0169, -0.1617,\n",
      "         0.0364, -0.1171, -0.0672, -0.0463, -0.1440, -0.0283, -0.1414, -0.0817,\n",
      "        -0.1216, -0.1434, -0.1007, -0.0829, -0.0847, -0.0944, -0.0996, -0.0635,\n",
      "        -0.0495, -0.0740, -0.1729, -0.0323, -0.0854, -0.1425, -0.2089, -0.1003,\n",
      "        -0.0466, -0.0387, -0.0221, -0.0157, -0.0886, -0.2177, -0.0581,  0.0595,\n",
      "        -0.1047, -0.0823, -0.2199, -0.0984, -0.2908, -0.1871, -0.1148, -0.0973,\n",
      "        -0.1013, -0.0822, -0.1887, -0.0266, -0.1300, -0.1948, -0.0408, -0.2314,\n",
      "        -0.1636, -0.1124, -0.1248, -0.0699, -0.0163, -0.2832, -0.1145,  0.0027,\n",
      "        -0.1888, -0.1967, -0.0513, -0.2947, -0.1073, -0.2505, -0.0530, -0.0608,\n",
      "        -0.0463, -0.1934, -0.0177, -0.0637, -0.1144, -0.0721, -0.1718, -0.0417,\n",
      "        -0.0331, -0.0515, -0.1317, -0.0541, -0.0484, -0.0255, -0.2226, -0.2640],\n",
      "       requires_grad=True)\n",
      "model.fc2.weight Parameter containing:\n",
      "tensor([[ 0.0617, -0.0207, -0.0055,  ..., -0.0534,  0.0972,  0.0407],\n",
      "        [-0.0431, -0.0206, -0.0187,  ..., -0.0870,  0.0977, -0.1209],\n",
      "        [-0.0105, -0.0413, -0.0954,  ..., -0.0213, -0.0295,  0.1017],\n",
      "        ...,\n",
      "        [-0.0516, -0.0333, -0.0910,  ..., -0.1997, -0.0205, -0.0331],\n",
      "        [-0.0958,  0.0095, -0.0828,  ..., -0.1066, -0.0843, -0.0756],\n",
      "        [-0.0494, -0.0661,  0.0050,  ..., -0.0309, -0.0066, -0.0007]],\n",
      "       requires_grad=True)\n",
      "model.fc2.bias Parameter containing:\n",
      "tensor([-0.0586,  0.0273, -0.1136, -0.1580,  0.0759, -0.0151, -0.1289, -0.0924,\n",
      "        -0.1406, -0.1931, -0.0327, -0.0626,  0.0438,  0.0052, -0.1264, -0.0300,\n",
      "        -0.1373, -0.1076, -0.1646, -0.0854, -0.1506, -0.0103, -0.0911, -0.1568,\n",
      "         0.0090,  0.1394, -0.0165, -0.0208, -0.1888, -0.2154, -0.0808, -0.0480,\n",
      "        -0.0734, -0.0221,  0.0096, -0.1215,  0.1224, -0.1054, -0.1913, -0.1089,\n",
      "        -0.1015, -0.0900, -0.0473, -0.1041,  0.2005, -0.0875, -0.0294, -0.1236,\n",
      "        -0.1231, -0.0887, -0.1263, -0.0206, -0.0857, -0.0749, -0.1271, -0.1248,\n",
      "        -0.1598, -0.0981, -0.0897, -0.1163, -0.1011, -0.1098, -0.0869, -0.1039,\n",
      "        -0.1788, -0.0650, -0.0108,  0.0945, -0.0697, -0.0281, -0.0777,  0.1335,\n",
      "        -0.0723, -0.0765, -0.0589, -0.1366,  0.0561,  0.0062, -0.0457, -0.0290,\n",
      "        -0.1270, -0.0240, -0.1593, -0.0959, -0.0761, -0.1504, -0.0690, -0.0551,\n",
      "         0.1908, -0.0803, -0.0667, -0.0409, -0.0764, -0.1517, -0.0691, -0.2351,\n",
      "        -0.0466, -0.1097, -0.0693, -0.0918, -0.1468, -0.1264, -0.0387, -0.1023,\n",
      "        -0.0439, -0.0507, -0.0263, -0.1296, -0.1235,  0.0011, -0.0481, -0.0746,\n",
      "        -0.0657, -0.1180,  0.0025, -0.0331, -0.1361, -0.1387, -0.1103, -0.0072,\n",
      "        -0.2670, -0.1363, -0.1631, -0.1512,  0.0261, -0.1542, -0.1045, -0.0202,\n",
      "        -0.1609, -0.0931,  0.0143, -0.1743, -0.2260, -0.1198, -0.0770, -0.0747,\n",
      "        -0.1854, -0.0619,  0.1270, -0.1070, -0.2038, -0.0219,  0.1675, -0.1450,\n",
      "        -0.2033, -0.1089, -0.1115, -0.0573,  0.0047, -0.0425, -0.1188, -0.0784,\n",
      "        -0.0383, -0.0942, -0.1198, -0.1460, -0.0356, -0.0608, -0.1236, -0.1402,\n",
      "        -0.0262, -0.1093, -0.0433, -0.0165,  0.0041, -0.1851, -0.1291, -0.0862,\n",
      "        -0.1168, -0.0615, -0.1029,  0.0065, -0.0597, -0.1950, -0.0752,  0.0615,\n",
      "        -0.2213, -0.0838, -0.1608, -0.0253, -0.1532,  0.1215, -0.0382, -0.0462,\n",
      "        -0.1183, -0.0361, -0.0428, -0.2290, -0.1497, -0.0876, -0.0697, -0.0954,\n",
      "        -0.0344, -0.0754, -0.0826, -0.0781, -0.1356, -0.0488, -0.0290,  0.0074,\n",
      "        -0.0681, -0.0388, -0.0414, -0.0653, -0.1387, -0.0598, -0.0282, -0.0805,\n",
      "        -0.1020, -0.1441, -0.0824,  0.0892, -0.0964, -0.1330,  0.0543, -0.2564,\n",
      "         0.0450, -0.0484,  0.2131, -0.1214, -0.0658, -0.1356, -0.0381, -0.0285,\n",
      "        -0.0532, -0.0727, -0.1070,  0.0354, -0.1620, -0.0786,  0.0440, -0.1285,\n",
      "        -0.0575,  0.0470, -0.0317,  0.0758,  0.0232, -0.0472, -0.1262, -0.0328,\n",
      "        -0.0144,  0.0938,  0.0134, -0.1410,  0.0428, -0.0209, -0.0260, -0.0186,\n",
      "        -0.0892, -0.0443, -0.0767, -0.1490, -0.1480, -0.1186, -0.0458, -0.1263,\n",
      "        -0.1641,  0.1784,  0.1654, -0.1276, -0.0930,  0.0967, -0.0030,  0.1737,\n",
      "        -0.1003,  0.0408, -0.0637, -0.0638, -0.1260, -0.1169, -0.0800, -0.0735,\n",
      "        -0.0711,  0.0950, -0.1241, -0.0669, -0.0091,  0.0249, -0.0109, -0.0405,\n",
      "        -0.0653, -0.1297, -0.0804,  0.0186, -0.0384,  0.0983, -0.0138, -0.2420,\n",
      "         0.1557,  0.1135, -0.1285,  0.0031, -0.0891, -0.1239,  0.1001, -0.1283,\n",
      "        -0.0818, -0.1163, -0.1021, -0.0407,  0.1043, -0.1202, -0.1327, -0.1896,\n",
      "         0.0155, -0.1048,  0.0330, -0.0196, -0.1875, -0.1176,  0.0993, -0.0639,\n",
      "        -0.0924, -0.1334, -0.1178, -0.0389, -0.1104, -0.1075, -0.1377,  0.2170,\n",
      "        -0.1102, -0.0712, -0.1436, -0.0729, -0.1219, -0.1149, -0.1100, -0.0878,\n",
      "         0.0977, -0.1124,  0.0387, -0.0455, -0.1795,  0.0275, -0.1283, -0.1315,\n",
      "        -0.0262, -0.0276,  0.1026, -0.0168, -0.0853, -0.0925, -0.0785,  0.0666,\n",
      "        -0.0918, -0.1036, -0.0788, -0.0965, -0.0861, -0.1285, -0.1595,  0.1989,\n",
      "        -0.0840, -0.0614, -0.1846, -0.1864, -0.0647, -0.1563, -0.0842, -0.0682,\n",
      "        -0.0538,  0.1119, -0.1632, -0.1025, -0.1416, -0.0736, -0.2115,  0.1580,\n",
      "        -0.1143, -0.1163, -0.0571, -0.0577, -0.0547, -0.1048,  0.0495, -0.1407,\n",
      "         0.1654, -0.1027,  0.0762,  0.0624,  0.2010, -0.1363,  0.1307, -0.0950,\n",
      "        -0.1076, -0.2051, -0.0922, -0.2311, -0.1171, -0.1124, -0.0037, -0.0798,\n",
      "        -0.1347, -0.0977,  0.0103, -0.0122,  0.0278, -0.0834, -0.1528, -0.0566],\n",
      "       requires_grad=True)\n",
      "model.fc3.weight Parameter containing:\n",
      "tensor([[-0.0243,  0.0169, -0.0685,  ...,  0.0395,  0.0595,  0.0319],\n",
      "        [ 0.0228, -0.0490, -0.0121,  ..., -0.0048,  0.0573,  0.0215],\n",
      "        [ 0.0116, -0.0314,  0.0457,  ..., -0.0435,  0.0099,  0.0002],\n",
      "        ...,\n",
      "        [-0.0070, -0.0180, -0.0182,  ..., -0.0030, -0.0072, -0.0437],\n",
      "        [-0.0358,  0.0575, -0.0424,  ..., -0.0432, -0.0500, -0.0139],\n",
      "        [ 0.0379,  0.0050,  0.0342,  ...,  0.0544, -0.0067, -0.0452]],\n",
      "       requires_grad=True)\n",
      "model.fc3.bias Parameter containing:\n",
      "tensor([-6.5060e-02, -1.3737e-01, -1.2233e-01, -1.1817e-01, -1.3448e-01,\n",
      "        -1.9651e-02, -2.8191e-02, -7.3340e-02, -1.0864e-01, -1.4187e-02,\n",
      "        -1.0604e-01, -8.3679e-02, -5.2821e-02, -3.0192e-02,  3.1005e-04,\n",
      "         6.2191e-02, -1.3617e-01, -8.3555e-02, -3.9021e-02,  1.7422e-01,\n",
      "        -7.9673e-02, -4.5290e-02, -6.9414e-02, -9.0829e-02, -1.1117e-01,\n",
      "        -5.1531e-02, -9.3418e-02, -4.3218e-02, -1.0480e-01, -5.5621e-02,\n",
      "        -4.0623e-02, -1.2966e-01, -3.2968e-02, -1.6689e-01, -5.4142e-02,\n",
      "        -5.9691e-02, -9.7196e-02, -1.3747e-01, -2.1065e-02, -4.3097e-02,\n",
      "        -5.2005e-02, -1.8192e-01, -1.2217e-01, -1.3367e-01, -9.2971e-02,\n",
      "        -1.3680e-01, -8.2228e-02, -1.2760e-01, -1.1756e-01, -1.1174e-01,\n",
      "        -1.0869e-01, -3.0776e-02,  1.2942e-02, -9.0422e-02, -1.1041e-01,\n",
      "        -1.1916e-01, -5.5330e-02, -4.1970e-02,  5.4824e-02, -1.0763e-02,\n",
      "        -4.1645e-02, -9.5659e-02, -7.1089e-02,  1.1240e-02, -4.9101e-02,\n",
      "        -2.8119e-02, -1.3447e-01, -7.3898e-02, -7.1606e-02, -2.7303e-02,\n",
      "        -1.6143e-01, -8.5164e-02, -5.3879e-02, -1.0604e-01, -4.6674e-02,\n",
      "        -7.1644e-02, -1.1148e-01, -8.6269e-02, -1.8988e-02, -6.1512e-02,\n",
      "        -6.9863e-02, -5.7747e-02, -7.9308e-02, -9.7732e-02, -6.4489e-02,\n",
      "        -1.4398e-02, -1.1425e-01, -9.9843e-02, -9.2532e-02, -1.2308e-01,\n",
      "        -3.4604e-02, -6.5205e-02, -2.1094e-01, -3.1009e-02,  1.1825e-02,\n",
      "        -4.0586e-02, -6.5850e-02, -7.0642e-02, -5.9020e-02, -5.6674e-02,\n",
      "        -1.5956e-01, -4.0207e-02, -6.7838e-02, -1.4197e-01, -8.1272e-02,\n",
      "        -3.6638e-02, -6.2609e-02, -9.4559e-02,  1.2533e-01, -1.1652e-02,\n",
      "        -7.1058e-02, -4.2593e-02, -1.2524e-01, -9.7380e-02, -1.0502e-01,\n",
      "        -1.6482e-01, -4.1048e-02, -3.0068e-02, -2.6197e-02, -7.6442e-02,\n",
      "        -9.6415e-02, -1.6581e-01, -6.0102e-02, -1.3003e-01, -1.6752e-01,\n",
      "        -2.3171e-01, -1.2314e-01, -4.8819e-02, -7.4864e-02, -5.5011e-02,\n",
      "        -1.8902e-01, -1.2552e-01,  1.4072e-02, -5.7948e-02, -6.2428e-02,\n",
      "        -7.7494e-02, -6.9780e-02, -7.0374e-02, -1.2617e-01, -1.2791e-01,\n",
      "        -8.1636e-02, -8.9502e-02, -5.2665e-02, -1.4034e-01, -1.2305e-01,\n",
      "        -1.0829e-01, -1.4377e-01, -7.4455e-02, -6.1671e-02, -1.3257e-01,\n",
      "        -2.3686e-02, -7.7007e-02, -1.0685e-01, -4.3054e-02, -1.2838e-01,\n",
      "        -9.5189e-02, -1.4785e-01, -5.3278e-02, -3.9638e-02, -1.4091e-01,\n",
      "        -9.6832e-02, -1.0529e-01, -5.4899e-02, -1.1004e-01, -2.2439e-02,\n",
      "        -8.6987e-02, -1.2482e-01, -1.0049e-01, -1.0754e-01, -4.3266e-02,\n",
      "        -5.8482e-03, -1.4729e-01, -2.4710e-02, -7.3405e-02, -1.3569e-01,\n",
      "        -1.1650e-01, -7.2682e-02, -4.9682e-02, -8.2770e-02, -1.2789e-01,\n",
      "        -9.0114e-02, -1.2650e-01, -1.1421e-01, -9.6622e-02, -1.1147e-01,\n",
      "        -3.9791e-02, -1.0179e-01, -7.3624e-02, -6.3793e-02, -1.1814e-01,\n",
      "        -1.4541e-01, -2.3166e-01, -4.7546e-02, -1.0438e-01, -1.4324e-01,\n",
      "        -7.0798e-02, -4.6493e-02, -1.5500e-01, -6.3347e-02, -1.1447e-01,\n",
      "        -8.2143e-02, -1.0955e-01, -4.6268e-02, -1.4299e-01, -8.8790e-02,\n",
      "        -9.0918e-02, -8.7603e-02, -9.2874e-02, -1.4462e-01, -7.6418e-02,\n",
      "        -3.6208e-03, -2.2995e-02, -3.0006e-02, -1.2402e-01, -1.1050e-01,\n",
      "         1.5316e-02, -1.1602e-01, -4.7173e-02, -6.1418e-02, -1.3527e-01,\n",
      "        -5.4426e-02, -2.5608e-02, -1.2063e-01,  1.4423e-01, -8.1974e-02,\n",
      "        -8.7590e-02, -3.1739e-02,  9.6158e-02, -9.0433e-02, -9.7476e-02,\n",
      "        -2.0467e-01, -1.1117e-01, -1.7517e-01, -1.3634e-01, -8.3532e-02,\n",
      "        -9.0128e-02, -4.0945e-02, -7.6464e-03, -7.4918e-02, -1.4466e-01,\n",
      "        -8.6794e-02, -1.4321e-02, -1.2589e-01, -5.1225e-02, -3.9838e-02,\n",
      "        -7.7594e-02, -2.6475e-02, -7.9385e-02, -1.9621e-02, -7.4395e-02,\n",
      "        -1.7856e-01, -8.2101e-02, -1.3445e-01,  1.3011e-01, -6.3344e-02,\n",
      "        -3.4122e-02, -3.8615e-01, -4.1581e-02, -4.9422e-02, -9.7187e-02,\n",
      "        -1.5422e-01, -5.9946e-02, -1.1976e-01, -4.2049e-02, -9.5623e-02,\n",
      "        -1.0174e-01,  6.4330e-02,  5.3158e-03, -4.9426e-02, -1.6188e-01,\n",
      "        -1.5779e-02, -6.5269e-02, -1.0092e-01, -5.3858e-02, -5.3121e-02,\n",
      "        -1.3882e-02, -1.2310e-01, -7.1289e-02, -1.4554e-01, -5.0488e-02,\n",
      "        -7.1784e-02, -1.3100e-01, -1.3381e-01, -6.0856e-02, -1.4981e-01,\n",
      "        -1.2157e-01, -2.6884e-02, -1.0891e-01, -4.2333e-02, -7.4283e-02,\n",
      "        -7.8601e-02, -3.5446e-03, -1.1859e-01, -9.6676e-02, -9.5355e-02,\n",
      "        -2.1598e-02, -3.5212e-02, -1.3223e-01, -1.0959e-02, -5.5307e-02,\n",
      "        -4.4610e-02, -1.2537e-02, -1.7943e-02, -5.6806e-02, -7.1083e-02,\n",
      "        -6.9322e-02, -1.6462e-01, -1.0251e-01, -9.9475e-02, -1.4402e-01,\n",
      "        -6.6856e-02, -3.4865e-02, -5.1768e-02,  1.4426e-02, -2.3817e-01,\n",
      "        -8.1339e-02, -4.7645e-02, -1.8659e-01, -5.4677e-02, -1.6266e-01,\n",
      "        -2.0986e-01, -1.7391e-01, -9.0870e-02, -1.3004e-01, -1.0124e-01,\n",
      "        -1.3237e-01, -1.3629e-01, -1.9727e-01, -1.5032e-01, -7.6257e-02,\n",
      "        -1.5320e-01, -1.3558e-01, -5.9320e-02, -9.2527e-02, -1.3073e-01,\n",
      "        -4.6331e-02, -1.4393e-01, -2.4881e-02, -1.1322e-01, -8.8065e-02,\n",
      "        -1.3607e-01, -1.2423e-01, -1.4824e-01, -3.4902e-02, -7.1713e-02,\n",
      "        -8.7508e-02, -9.3016e-02, -1.0140e-01, -1.6934e-02, -2.1162e-02,\n",
      "        -8.9011e-02, -4.0388e-02, -6.1202e-02, -3.7655e-02, -4.1985e-02,\n",
      "        -1.4318e-01, -9.6835e-02, -6.2631e-02, -2.6067e-02, -1.3500e-01,\n",
      "        -4.4257e-02, -6.6028e-02, -1.9793e-01, -6.4324e-02, -4.3981e-02,\n",
      "        -1.2566e-01, -1.6032e-01, -2.2938e-02, -1.4717e-01, -1.3321e-01,\n",
      "        -2.0405e-02, -5.2347e-02, -6.1749e-02, -1.1747e-01, -5.6391e-02,\n",
      "        -4.4389e-02, -1.0006e-01, -6.5834e-02, -1.4787e-01, -3.4172e-02,\n",
      "        -1.1116e-01, -1.4771e-01, -1.8087e-02, -1.4085e-01, -1.2246e-01,\n",
      "        -1.1991e-01, -1.1471e-01,  3.1763e-02, -1.1908e-01, -1.3387e-01,\n",
      "        -1.0183e-01, -4.4191e-02, -1.4344e-01, -8.9687e-02, -1.8765e-02,\n",
      "        -9.4515e-02, -1.3122e-01, -8.3404e-02, -1.4251e-02, -4.0394e-02],\n",
      "       requires_grad=True)\n",
      "model.fc4.weight Parameter containing:\n",
      "tensor([[-1.6948e-02,  6.7777e-03, -3.4087e-02,  2.7091e-02,  1.4756e-02,\n",
      "         -6.1904e-03,  1.2332e-03, -1.6525e-03, -8.2487e-03,  2.7170e-03,\n",
      "         -9.9435e-03, -1.9156e-02,  1.6648e-02,  1.9344e-03,  1.7867e-03,\n",
      "          5.7408e-03,  3.7788e-02,  3.3316e-02, -3.7617e-03, -4.2706e-02,\n",
      "         -1.7911e-02,  4.4325e-03,  2.2335e-03,  1.1069e-02,  7.4987e-03,\n",
      "         -4.2486e-03, -6.2900e-03, -8.2237e-03, -1.0035e-03,  1.7974e-03,\n",
      "          1.5771e-02,  7.7265e-03, -1.2002e-03, -8.0454e-03, -4.5821e-02,\n",
      "          8.1308e-04,  8.7323e-03,  3.4344e-02,  3.2761e-04,  1.0009e-02,\n",
      "          9.5317e-04, -3.2249e-03, -1.2030e-02, -5.0646e-03,  2.1410e-03,\n",
      "          4.7105e-03, -3.7585e-03,  4.6372e-04,  4.7846e-03,  8.5710e-04,\n",
      "         -1.4354e-02,  6.4369e-03,  1.9612e-03,  1.4304e-02,  9.2998e-03,\n",
      "          4.7228e-03,  2.3588e-03, -4.8491e-03, -1.3703e-02,  5.8900e-03,\n",
      "          6.5981e-03,  7.2303e-03,  2.8276e-03,  6.7519e-03,  8.6915e-03,\n",
      "          2.7350e-03, -1.0046e-02,  9.5482e-05,  7.1625e-03,  1.3358e-03,\n",
      "          1.3654e-02,  3.6286e-03,  7.8098e-04,  1.3068e-02,  7.0355e-04,\n",
      "         -7.1702e-03, -2.5451e-02,  1.0299e-02, -1.6096e-02,  1.4676e-03,\n",
      "         -4.7348e-03, -1.2223e-02,  5.0424e-03,  7.6946e-03, -1.1626e-02,\n",
      "          4.8881e-05,  7.5583e-03,  2.5586e-02,  1.9218e-03, -1.8537e-02,\n",
      "         -1.0399e-02,  8.9138e-03, -1.5721e-02,  3.2191e-03, -2.8294e-03,\n",
      "          1.0204e-03, -4.3059e-03,  7.1204e-03,  2.0182e-04,  4.1919e-03,\n",
      "         -2.2124e-02,  3.5417e-03, -8.1471e-03,  3.1370e-03, -3.1868e-03,\n",
      "         -3.7027e-03,  5.8096e-03,  2.3209e-03, -2.9002e-02, -1.6493e-03,\n",
      "         -1.1805e-02,  4.3009e-05,  6.5002e-03,  2.6667e-02, -5.2924e-03,\n",
      "          1.2937e-02,  5.4348e-03, -9.1465e-04,  1.1209e-02, -2.9986e-03,\n",
      "         -1.1441e-02, -3.4001e-03,  1.3043e-02,  3.0240e-02,  5.8105e-04,\n",
      "         -5.2559e-02,  2.6104e-02,  6.5528e-03, -5.2880e-04,  1.3613e-02,\n",
      "          2.1445e-02,  1.5459e-02,  1.6654e-04,  5.3462e-03, -6.8477e-03,\n",
      "          4.5790e-03,  1.1903e-03, -1.7528e-02, -1.9877e-02, -7.3668e-04,\n",
      "          2.2162e-02,  1.7927e-02, -2.2374e-02, -1.0041e-02,  9.1666e-03,\n",
      "          1.1955e-02,  1.8952e-02,  1.7745e-02,  6.4581e-03, -1.2019e-02,\n",
      "          6.6326e-03, -1.1597e-02, -4.2215e-03,  4.1279e-03, -9.7722e-03,\n",
      "          9.5286e-03,  1.6876e-02,  1.1689e-02,  2.5978e-02, -1.5827e-03,\n",
      "          3.5428e-02, -1.5182e-02, -4.9937e-03,  8.7214e-03,  9.0966e-03,\n",
      "          2.2108e-02, -1.3879e-02, -1.0830e-02,  1.2640e-02, -1.0769e-02,\n",
      "          1.9430e-02,  2.8380e-02,  2.1814e-02,  2.0529e-02, -4.9860e-03,\n",
      "          9.0868e-03,  1.7126e-03, -9.9428e-03,  1.7495e-02,  9.1415e-04,\n",
      "          1.8023e-02, -6.8504e-03, -1.5542e-02, -2.3260e-02,  1.0933e-02,\n",
      "         -3.6024e-04, -5.4119e-03,  1.1789e-02, -3.8558e-04,  2.9195e-02,\n",
      "         -6.2446e-03,  1.8848e-03,  1.4222e-02, -3.7019e-02,  3.7170e-02,\n",
      "         -9.6884e-03,  7.4561e-03,  6.5098e-03,  2.9066e-03, -2.7585e-02,\n",
      "          6.6580e-03, -2.3275e-03, -1.4499e-03,  3.8212e-02,  1.9532e-02,\n",
      "         -5.5326e-03,  1.7564e-02,  4.2408e-02, -8.4647e-03,  1.3083e-02,\n",
      "          1.5473e-02, -5.4656e-03, -1.0464e-02, -2.1814e-02,  9.7381e-03,\n",
      "          2.1759e-02, -1.7951e-03,  7.3774e-03,  2.3659e-03, -1.9366e-03,\n",
      "          1.5994e-02,  3.2214e-03,  5.3608e-02,  4.1885e-02, -1.4857e-03,\n",
      "          2.3854e-04,  5.6716e-02, -2.7430e-02,  1.4121e-03, -2.0690e-02,\n",
      "         -6.1329e-03,  1.7851e-02,  1.4455e-02, -1.3889e-02,  2.7597e-02,\n",
      "         -4.5433e-03, -2.9929e-03,  1.3084e-03,  2.0599e-03,  2.8182e-02,\n",
      "         -2.4939e-02, -2.6456e-03,  1.6123e-02, -2.2325e-02,  3.1439e-02,\n",
      "          5.6967e-04, -1.6100e-02, -8.1197e-03,  5.9729e-04,  1.0686e-02,\n",
      "         -4.0591e-03, -6.2736e-03,  6.7180e-03,  3.5315e-02, -4.1610e-02,\n",
      "          6.4612e-03,  4.6618e-02,  1.2033e-02,  5.0015e-03,  2.1796e-02,\n",
      "          6.0194e-03,  3.8867e-02, -7.1109e-03, -1.0987e-04,  3.9575e-03,\n",
      "         -1.1963e-02,  4.3116e-03, -2.0178e-03, -2.2099e-04,  2.2619e-02,\n",
      "          1.6143e-03,  6.9509e-05, -2.0801e-02,  2.4203e-03, -2.2298e-03,\n",
      "         -5.1929e-03, -9.1270e-03,  3.2422e-03,  6.9989e-03,  1.3288e-03,\n",
      "         -9.7125e-04,  1.1745e-02,  1.4621e-02, -5.9357e-04,  2.1708e-02,\n",
      "         -1.5597e-02,  6.7396e-04,  2.5318e-02, -6.2011e-03, -1.5228e-03,\n",
      "         -4.0702e-03,  3.6379e-02,  6.0185e-03, -2.1992e-02,  9.1930e-03,\n",
      "         -4.4039e-03,  1.6112e-03, -6.0203e-03,  6.2862e-03,  1.2797e-03,\n",
      "          2.9311e-03, -4.5929e-04,  1.6028e-02,  4.3343e-03, -3.9988e-04,\n",
      "          2.4942e-03,  8.9664e-04, -2.2333e-04,  5.4742e-03,  2.3057e-02,\n",
      "          1.8022e-02, -2.8763e-04,  1.8714e-03,  3.8938e-03, -5.7814e-02,\n",
      "          1.8389e-02, -6.9004e-04,  4.9484e-03,  3.5371e-03, -8.5987e-03,\n",
      "          8.1946e-03,  2.2565e-03,  2.7927e-02,  1.3128e-03,  1.5817e-02,\n",
      "          2.3021e-02, -7.4358e-03, -5.1596e-03, -5.0452e-03,  7.4355e-03,\n",
      "         -2.5751e-03,  1.0625e-02,  1.7179e-02,  2.5709e-02,  3.8653e-03,\n",
      "         -1.7080e-03,  1.0982e-02,  1.8122e-02, -4.5234e-02,  3.4528e-03,\n",
      "          2.9307e-02,  1.8999e-02, -1.5453e-02, -2.5078e-04,  1.0606e-02,\n",
      "         -4.8279e-03,  1.0312e-02,  1.3214e-02,  4.8029e-03,  7.1715e-04,\n",
      "          1.7131e-02, -1.7730e-03,  5.2036e-02,  3.7097e-03,  8.4141e-04,\n",
      "         -1.1955e-03,  1.0667e-02,  1.2955e-04, -3.0174e-03,  8.3160e-03,\n",
      "          9.3324e-04, -2.1937e-03,  1.6670e-04,  4.9383e-03,  1.7855e-02,\n",
      "          1.2091e-03,  6.6536e-03,  1.4018e-02, -1.1139e-03,  1.6963e-02,\n",
      "          2.5139e-03,  1.0268e-02,  6.9499e-03, -1.1723e-02, -1.1771e-02,\n",
      "          4.9253e-03, -3.1280e-02,  8.9535e-03,  1.6612e-02,  2.8318e-03,\n",
      "          9.4387e-03,  1.8779e-02, -5.8383e-03,  8.4802e-03, -2.2365e-03,\n",
      "          7.6097e-03, -5.9300e-03, -5.7370e-04,  1.1318e-02,  3.0693e-03,\n",
      "         -1.0942e-02,  1.0308e-02,  4.7201e-03,  1.3026e-02, -2.7002e-03,\n",
      "          1.7546e-02, -1.7882e-03,  3.6919e-02, -4.3202e-04,  1.5103e-02]],\n",
      "       requires_grad=True)\n",
      "model.fc4.bias Parameter containing:\n",
      "tensor([0.0606], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for name, parameter in dnis.named_parameters():\n",
    "    print (name, parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3991fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "def val(model, dataloader):\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    pred_arr = np.array([])\n",
    "    label_arr = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for itr, batch in tqdm(enumerate(dataloader)):\n",
    "            batch = [item.to(device) for item in batch]\n",
    "            feature_ids, feature_vals, labels = batch\n",
    "            outputs = model(feature_ids, feature_vals)\n",
    "            loss = torch.nn.BCEWithLogitsLoss()(outputs.squeeze(), labels.squeeze())\n",
    "            running_loss += loss.data.detach().cpu().item()\n",
    "            pred_arr = np.hstack(\n",
    "                [pred_arr, outputs.data.detach().cpu()]) if pred_arr.size else outputs.data.detach().cpu()\n",
    "            label_arr = np.hstack(\n",
    "                [label_arr, labels.data.detach().cpu()]) if label_arr.size else labels.data.detach().cpu()\n",
    "        val_loss = running_loss / (itr + 1)\n",
    "        torch.cuda.empty_cache()\n",
    "    if args.dataset_type == \"ava\":\n",
    "        auc = roc_auc_score(label_arr, pred_arr)\n",
    "        return val_loss, auc\n",
    "    return val_loss, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4dac050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f01e69757c2f47dba8ce777c6a29b626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.739168377419715, 0.7655923347969603)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnis=dnis.to(device)\n",
    "val(dnis,test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93770b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_checkpoint = dnis.alpha.data.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e2a0100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.9068e-01, 7.4982e-01, 6.5229e-02, 2.8706e-01, 4.5175e-01, 3.8904e-02,\n",
       "         6.0947e-02, 9.4172e-01, 1.1652e-01, 1.3816e-01, 1.0624e-01, 4.5850e-01,\n",
       "         4.4884e-01, 7.0286e-01, 8.5268e-02, 2.9903e-01, 1.0281e-01, 1.5134e-01,\n",
       "         1.5441e-01, 5.2884e-02, 7.3251e-02, 3.7504e-01, 6.9772e-02, 1.7425e-01,\n",
       "         7.6491e-01, 1.4102e-01, 5.4107e-01, 4.8125e-02, 1.2655e-01, 1.0688e-01,\n",
       "         4.5544e-02, 3.7616e-01, 4.8382e-01, 7.0013e-01, 5.8183e-02, 4.5206e-03,\n",
       "         7.8600e-02, 1.0800e-01, 5.4182e-01, 6.2045e-01, 5.4111e-02, 1.3194e-01,\n",
       "         3.8040e-01, 3.9374e-02, 4.1311e-03, 4.2428e-01, 0.0000e+00, 1.0000e+00,\n",
       "         2.9202e-01, 1.1475e-01, 4.7421e-01, 8.5632e-01, 6.2379e-01, 1.5601e-01,\n",
       "         3.6184e-01, 1.8883e-01, 3.6037e-02, 4.6095e-01, 2.8671e-01, 2.5716e-02,\n",
       "         6.1751e-01, 3.1376e-01, 3.8785e-02, 1.2487e-01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0466e-02, 3.8053e-03, 4.8646e-03,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7962e-03, 0.0000e+00,\n",
       "         1.7456e-03, 1.1921e-03, 1.2764e-02, 0.0000e+00, 0.0000e+00, 3.9439e-02,\n",
       "         1.9016e-02, 0.0000e+00, 2.1656e-03, 8.9960e-03, 0.0000e+00, 1.8675e-02,\n",
       "         1.6556e-02, 1.0185e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         7.1943e-03, 4.9236e-03, 5.8158e-03, 0.0000e+00, 2.4732e-02, 0.0000e+00,\n",
       "         7.0980e-03, 0.0000e+00, 1.6308e-02, 0.0000e+00, 1.1993e-02, 0.0000e+00,\n",
       "         3.0525e-03, 4.1716e-03, 1.1671e-02, 0.0000e+00, 0.0000e+00, 1.6625e-02,\n",
       "         0.0000e+00, 8.1553e-05, 4.1380e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         7.1874e-03, 0.0000e+00, 6.9782e-04, 6.7532e-03, 0.0000e+00, 1.2081e-02,\n",
       "         0.0000e+00, 2.9366e-03, 6.4828e-02, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 7.2035e-03, 0.0000e+00, 1.0301e-02, 1.6835e-03,\n",
       "         2.4703e-03, 0.0000e+00, 0.0000e+00, 1.5935e-02, 6.1639e-03, 2.4575e-02,\n",
       "         0.0000e+00, 0.0000e+00, 2.0380e-02, 0.0000e+00, 5.9168e-03, 1.8990e-02,\n",
       "         0.0000e+00, 4.0948e-02, 1.6606e-02, 5.0269e-03, 3.9387e-03, 0.0000e+00,\n",
       "         0.0000e+00, 1.3623e-02, 1.1564e-02, 1.2298e-03, 9.5475e-03, 6.4048e-03,\n",
       "         9.1596e-03, 0.0000e+00, 1.3643e-02, 0.0000e+00, 1.4355e-02, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.5290e-02, 0.0000e+00, 1.3582e-02, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 9.9261e-03, 0.0000e+00, 4.1403e-04, 1.8210e-02,\n",
       "         3.3149e-03, 0.0000e+00, 3.1715e-02, 4.4614e-03, 5.3758e-03, 0.0000e+00,\n",
       "         3.3330e-03, 5.0900e-03, 8.3437e-03, 0.0000e+00, 1.2708e-02, 3.1442e-02,\n",
       "         2.5010e-02, 0.0000e+00, 4.8547e-02, 0.0000e+00],\n",
       "        [7.8030e-03, 0.0000e+00, 8.8367e-03, 1.1028e-02, 0.0000e+00, 1.6500e-02,\n",
       "         0.0000e+00, 6.0868e-03, 2.7326e-03, 0.0000e+00, 4.0200e-03, 5.3879e-03,\n",
       "         1.0030e-02, 5.1090e-03, 8.0209e-03, 3.4246e-03, 4.3654e-03, 4.0868e-03,\n",
       "         7.8400e-03, 1.8859e-02, 0.0000e+00, 2.6059e-02, 6.3329e-03, 8.9396e-03,\n",
       "         7.9628e-03, 6.1231e-03, 6.3084e-03, 0.0000e+00, 7.9698e-04, 5.1872e-03,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3300e-03, 0.0000e+00, 2.3333e-03,\n",
       "         0.0000e+00, 1.2482e-02, 0.0000e+00, 1.2749e-03, 0.0000e+00, 7.5244e-03,\n",
       "         0.0000e+00, 4.4921e-03, 6.1712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.6949e-03, 9.8949e-03, 0.0000e+00, 8.0005e-03, 0.0000e+00, 0.0000e+00,\n",
       "         7.3086e-03, 5.8687e-03, 6.7976e-05, 0.0000e+00, 0.0000e+00, 4.9498e-03,\n",
       "         1.1147e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7242e-04, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3328e-03,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5545e-04, 0.0000e+00,\n",
       "         1.9385e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 5.0741e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3378e-03,\n",
       "         5.9076e-04, 1.0756e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1658e-04,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3101310e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8906775712966919"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_checkpoint[0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a388e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 1\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 2\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 3\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 4\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n",
      "block 5\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(alpha_checkpoint):\n",
    "    for item in row:\n",
    "        print(\"block %d\"%(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd7e3dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8906775712966919\n",
      "0.7498247027397156\n",
      "0.06522924453020096\n",
      "0.2870582044124603\n",
      "0.45175084471702576\n",
      "0.03890378773212433\n",
      "0.06094735115766525\n",
      "0.941724956035614\n",
      "0.1165192574262619\n",
      "0.13815782964229584\n",
      "0.10624378174543381\n",
      "0.45849746465682983\n",
      "0.4488407075405121\n",
      "0.7028577327728271\n",
      "0.08526826649904251\n",
      "0.29902926087379456\n",
      "0.10280556976795197\n",
      "0.15133629739284515\n",
      "0.15441220998764038\n",
      "0.05288417637348175\n",
      "0.07325130701065063\n",
      "0.3750394582748413\n",
      "0.06977176666259766\n",
      "0.1742529571056366\n",
      "0.7649118304252625\n",
      "0.1410234272480011\n",
      "0.5410747528076172\n",
      "0.048125170171260834\n",
      "0.12654587626457214\n",
      "0.10687520354986191\n",
      "0.04554407298564911\n",
      "0.37616461515426636\n",
      "0.48382243514060974\n",
      "0.7001307010650635\n",
      "0.058183200657367706\n",
      "0.004520602058619261\n",
      "0.07860010117292404\n",
      "0.10799648612737656\n",
      "0.5418176651000977\n",
      "0.62044757604599\n",
      "0.05411115661263466\n",
      "0.13194425404071808\n",
      "0.3804042935371399\n",
      "0.03937441483139992\n",
      "0.00413112947717309\n",
      "0.4242765009403229\n",
      "0.0\n",
      "1.0\n",
      "0.2920246720314026\n",
      "0.114754818379879\n",
      "0.4742065370082855\n",
      "0.8563236594200134\n",
      "0.62379390001297\n",
      "0.156009703874588\n",
      "0.3618409335613251\n",
      "0.18883304297924042\n",
      "0.03603656589984894\n",
      "0.46094977855682373\n",
      "0.2867068648338318\n",
      "0.025716420263051987\n",
      "0.6175123453140259\n",
      "0.3137592077255249\n",
      "0.03878549486398697\n",
      "0.12486574798822403\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.04046565294265747\n",
      "0.003805264364928007\n",
      "0.004864579997956753\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0037961655762046576\n",
      "0.0\n",
      "0.0017455941997468472\n",
      "0.0011920809047296643\n",
      "0.01276396494358778\n",
      "0.0\n",
      "0.0\n",
      "0.03943933919072151\n",
      "0.019016386941075325\n",
      "0.0\n",
      "0.0021655906457453966\n",
      "0.008996031247079372\n",
      "0.0\n",
      "0.018675392493605614\n",
      "0.01655571535229683\n",
      "0.001018520793877542\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007194302510470152\n",
      "0.004923565778881311\n",
      "0.005815829150378704\n",
      "0.0\n",
      "0.024732153862714767\n",
      "0.0\n",
      "0.007098025176674128\n",
      "0.0\n",
      "0.016308076679706573\n",
      "0.0\n",
      "0.01199305895715952\n",
      "0.0\n",
      "0.003052513115108013\n",
      "0.004171582404524088\n",
      "0.011671078391373158\n",
      "0.0\n",
      "0.0\n",
      "0.01662466861307621\n",
      "0.0\n",
      "8.15526582300663e-05\n",
      "0.04138024151325226\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.007187400944530964\n",
      "0.0\n",
      "0.0006978230085223913\n",
      "0.006753178313374519\n",
      "0.0\n",
      "0.012080894783139229\n",
      "0.0\n",
      "0.002936595818027854\n",
      "0.0648278221487999\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0072035156190395355\n",
      "0.0\n",
      "0.010300785303115845\n",
      "0.0016835161950439215\n",
      "0.0024703398812562227\n",
      "0.0\n",
      "0.0\n",
      "0.015935402363538742\n",
      "0.006163908634334803\n",
      "0.024575235322117805\n",
      "0.0\n",
      "0.0\n",
      "0.02038019895553589\n",
      "0.0\n",
      "0.0059168217703700066\n",
      "0.01898985356092453\n",
      "0.0\n",
      "0.0409475639462471\n",
      "0.01660614274442196\n",
      "0.005026902537792921\n",
      "0.003938679583370686\n",
      "0.0\n",
      "0.0\n",
      "0.013622932136058807\n",
      "0.011563590727746487\n",
      "0.0012297541834414005\n",
      "0.00954748596996069\n",
      "0.006404847372323275\n",
      "0.009159625507891178\n",
      "0.0\n",
      "0.013643006794154644\n",
      "0.0\n",
      "0.014355139806866646\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.015290155075490475\n",
      "0.0\n",
      "0.01358160749077797\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.009926088154315948\n",
      "0.0\n",
      "0.0004140263481531292\n",
      "0.01821041852235794\n",
      "0.0033148517832159996\n",
      "0.0\n",
      "0.03171537443995476\n",
      "0.0044613550417125225\n",
      "0.005375823471695185\n",
      "0.0\n",
      "0.003333011409267783\n",
      "0.005090007558465004\n",
      "0.008343658410012722\n",
      "0.0\n",
      "0.012707831338047981\n",
      "0.031442444771528244\n",
      "0.025010062381625175\n",
      "0.0\n",
      "0.04854654520750046\n",
      "0.0\n",
      "0.007803018670529127\n",
      "0.0\n",
      "0.008836734108626842\n",
      "0.011027995496988297\n",
      "0.0\n",
      "0.016500430181622505\n",
      "0.0\n",
      "0.006086822133511305\n",
      "0.002732600551098585\n",
      "0.0\n",
      "0.004019975662231445\n",
      "0.005387858022004366\n",
      "0.010029669851064682\n",
      "0.005109033081680536\n",
      "0.008020862005650997\n",
      "0.0034246358554810286\n",
      "0.004365420434623957\n",
      "0.004086783155798912\n",
      "0.007840019650757313\n",
      "0.0188591405749321\n",
      "0.0\n",
      "0.02605886198580265\n",
      "0.006332913413643837\n",
      "0.00893960427492857\n",
      "0.007962753996253014\n",
      "0.006123072933405638\n",
      "0.006308389827609062\n",
      "0.0\n",
      "0.0007969787693582475\n",
      "0.005187233444303274\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0033300365321338177\n",
      "0.0\n",
      "0.0023332657292485237\n",
      "0.0\n",
      "0.012482025660574436\n",
      "0.0\n",
      "0.0012749196030199528\n",
      "0.0\n",
      "0.007524356711655855\n",
      "0.0\n",
      "0.004492131527513266\n",
      "0.006171227432787418\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0036949445493519306\n",
      "0.009894901886582375\n",
      "0.0\n",
      "0.008000488393008709\n",
      "0.0\n",
      "0.0\n",
      "0.007308573927730322\n",
      "0.0058687240816652775\n",
      "6.79758086334914e-05\n",
      "0.0\n",
      "0.0\n",
      "0.004949809983372688\n",
      "0.001114733750000596\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.000872415432240814\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0013327626511454582\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0005554467788897455\n",
      "0.0\n",
      "0.001938466215506196\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.00507408706471324\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0023377765901386738\n",
      "0.000590763462241739\n",
      "0.010755973868072033\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0008165807812474668\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i,row in enumerate(alpha_checkpoint):\n",
    "    for item in row:\n",
    "        print(item.item())\n",
    "# for item in alpha_checkpoint[0]:\n",
    "#     print(item.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a18b552",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpha_block_mask = alpha_checkpoint.repeat_interleave(dnis.feature_nums.to(dnis.alpha).long(),\n",
    "                                                     #   dim=0).repeat_interleave(\n",
    "  # dnis.embed_dims.to(dnis.alpha).long(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1284d92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dnis.feature_embeddings.weight.data *= alpha_block_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e712fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dnis.alpha.data = torch.ones_like(dnis.alpha.data).to(dnis.alpha.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a64e8d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf509d0dd84648f3a7b5e195dcd2c708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.739168377419715, 0.7655923347969603)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val(dnis,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "049d1774",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.reshape(dnis.feature_embeddings.weight.data.abs().detach().cpu(),(-1))\n",
    "arr = np.sort(arr)\n",
    "embedding_checkpoint = dnis.feature_embeddings.weight.data.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22223141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.1685e-02,  1.0090e-01,  1.0588e-01,  ...,  6.8006e-01,\n",
       "          1.7277e-01, -5.5160e-01],\n",
       "        [ 1.2717e-01, -2.9075e-02,  6.5321e-03,  ...,  7.4864e-02,\n",
       "          5.3864e-02, -2.5512e-01],\n",
       "        [-3.6245e-01,  5.7768e-01,  9.3803e-02,  ..., -9.2616e-02,\n",
       "         -2.0556e-01, -2.1883e-01],\n",
       "        ...,\n",
       "        [ 5.9820e-04,  2.6121e-04, -8.9212e-04,  ...,  4.4282e-04,\n",
       "         -4.5947e-04, -1.1509e-03],\n",
       "        [ 1.9591e-04, -1.4190e-04,  5.2632e-04,  ...,  1.5511e-04,\n",
       "          7.5685e-04, -5.3025e-04],\n",
       "        [-5.3668e-03, -4.9665e-03,  2.4543e-03,  ...,  8.1259e-03,\n",
       "          4.3659e-03, -8.2888e-03]], device='cuda:0')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnis.feature_embeddings.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bff181c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98847296\n",
      " threshold: 5.919550960520326e-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "311ceb6014064093aabe79ccab839e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned: 98%, loss: 0.739168377419715, auc: 0.7655923347969603\n"
     ]
    }
   ],
   "source": [
    "print(torch.nonzero(dnis.feature_embeddings.weight.data).size(0))\n",
    "threshold = arr[int(arr.shape[0]*0/100)]\n",
    "print(f\" threshold: {threshold}\")\n",
    "dnis.feature_embeddings.weight.data = embedding_checkpoint.clone().detach()\n",
    "dnis.feature_embeddings.weight.data[dnis.feature_embeddings.weight.data.abs()<threshold]=0\n",
    "loss, auc = val(dnis,test_dataloader)\n",
    "print(f\"pruned: {98}%, loss: {loss}, auc: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b1c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25faa8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dnis(\n",
       "  (feature_embeddings): Embedding(1544489, 64)\n",
       "  (model): DeepFM(\n",
       "    (feature_biases): Embedding(1544489, 1)\n",
       "    (fc1): Linear(in_features=1472, out_features=400, bias=True)\n",
       "    (fc2): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (fc3): Linear(in_features=400, out_features=400, bias=True)\n",
       "    (fc4): Linear(in_features=400, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnis.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "97614f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "def train_weights(model, batch,optimizer):\n",
    "        model.train()\n",
    "        # update weights and keep gradients of w'/alpha\n",
    "        feature_ids, feature_vals, labels = batch\n",
    "        outputs =  model(feature_ids, feature_vals)\n",
    "        loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.alpha.grad.data.zero_()\n",
    "        return loss.data.detach().cpu().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b54a9b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98847296\n"
     ]
    }
   ],
   "source": [
    "print(torch.nonzero(dnis.feature_embeddings.weight.data).size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1051454a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27081a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbffb1c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ca8cc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6910\n",
      "1975\n",
      "988\n"
     ]
    }
   ],
   "source": [
    "#Retrain the subnetwork when the pruned ratio > 98% (Optional)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size, shuffle=True, num_workers=8, pin_memory=True)\n",
    "num_epochs = 2\n",
    "print(len(train_dataloader))\n",
    "print(len(val_dataloader))\n",
    "print(len(test_dataloader))\n",
    "def retrain(model,dataloader):\n",
    "    parameters_w = [parameter for name, parameter in model.named_parameters() if 'alpha' not in name]\n",
    "    #parameters_w = [parameter for name, parameter in model.named_parameters() if 'bias' not in name]\n",
    "    optimizer_w = torch.optim.Adam(parameters_w, lr=0.001)\n",
    "    scheduler_w = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_w, 'min', verbose=True,patience=0)\n",
    "    for epoch in range(num_epochs):\n",
    "            print(f\"Starting epoch: {epoch} | phase: train | : {time.strftime('%H:%M:%S')}\")\n",
    "            model.train()\n",
    "            running_loss = 0\n",
    "            # if epoch == 8:\n",
    "            #     self.optimizer_w.param_groups[0]['lr'] *= 0.1\n",
    "            for itr, batch in tqdm(enumerate(dataloader)):\n",
    "                batch = [item.to(device) for item in batch]\n",
    "                feature_ids, feature_vals, labels = batch\n",
    "                outputs = model(feature_ids, feature_vals).squeeze()\n",
    "                loss = criterion(outputs, labels.squeeze())\n",
    "                loss.backward()\n",
    "                optimizer_w.step()\n",
    "                model.zero_grad()\n",
    "                running_loss += loss.item()\n",
    "            epoch_loss = running_loss / itr\n",
    "            print(f\"training loss of epoch {epoch}: {epoch_loss}\")\n",
    "            torch.cuda.empty_cache()\n",
    "            val_loss, val_auc = val(dnis,val_dataloader)\n",
    "            print(f\"val loss of epoch {epoch}: {val_loss}\")\n",
    "            print(f\"val auc of epoch {epoch}: {val_auc}\")\n",
    "            loss, auc = val(dnis,test_dataloader)\n",
    "            print(f\"loss: {loss}, auc: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a512509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0 | phase: train | : 21:31:13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b5df3a1282480fbfbf77ff6515b844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss of epoch 0: 0.3780977173675623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff29f0a318a84b0f8f209e430f35c721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss of epoch 0: 0.3820227979859219\n",
      "val auc of epoch 0: 0.7766510880341078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ed62c8904e4d40a758b2f0d335ef2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.38159348996665315, auc: 0.7770365541575974\n",
      "Starting epoch: 1 | phase: train | : 21:40:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25a69b3b63240bebf0656df03a881c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss of epoch 1: 0.368109363509874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca518da7cd59443ca14eb59ad7e926b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss of epoch 1: 0.38172210052043576\n",
      "val auc of epoch 1: 0.7777114231625945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628858c0e41e46198684a21fea32df6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.38134933993039344, auc: 0.7780102989736531\n",
      "98847296\n"
     ]
    }
   ],
   "source": [
    "retrain(dnis,train_dataloader)\n",
    "print(torch.nonzero(dnis.feature_embeddings.weight.data).size(0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04286cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8.9068e-01, 7.4982e-01, 6.5229e-02, 2.8706e-01, 4.5175e-01, 3.8904e-02,\n",
      "         6.0947e-02, 9.4172e-01, 1.1652e-01, 1.3816e-01, 1.0624e-01, 4.5850e-01,\n",
      "         4.4884e-01, 7.0286e-01, 8.5268e-02, 2.9903e-01, 1.0281e-01, 1.5134e-01,\n",
      "         1.5441e-01, 5.2884e-02, 7.3251e-02, 3.7504e-01, 6.9772e-02, 1.7425e-01,\n",
      "         7.6491e-01, 1.4102e-01, 5.4107e-01, 4.8125e-02, 1.2655e-01, 1.0688e-01,\n",
      "         4.5544e-02, 3.7616e-01, 4.8382e-01, 7.0013e-01, 5.8183e-02, 4.5206e-03,\n",
      "         7.8600e-02, 1.0800e-01, 5.4182e-01, 6.2045e-01, 5.4111e-02, 1.3194e-01,\n",
      "         3.8040e-01, 3.9374e-02, 4.1311e-03, 4.2428e-01, 0.0000e+00, 1.0000e+00,\n",
      "         2.9202e-01, 1.1475e-01, 4.7421e-01, 8.5632e-01, 6.2379e-01, 1.5601e-01,\n",
      "         3.6184e-01, 1.8883e-01, 3.6037e-02, 4.6095e-01, 2.8671e-01, 2.5716e-02,\n",
      "         6.1751e-01, 3.1376e-01, 3.8785e-02, 1.2487e-01],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 4.0466e-02, 3.8053e-03, 4.8646e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.7962e-03, 0.0000e+00,\n",
      "         1.7456e-03, 1.1921e-03, 1.2764e-02, 0.0000e+00, 0.0000e+00, 3.9439e-02,\n",
      "         1.9016e-02, 0.0000e+00, 2.1656e-03, 8.9960e-03, 0.0000e+00, 1.8675e-02,\n",
      "         1.6556e-02, 1.0185e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.1943e-03, 4.9236e-03, 5.8158e-03, 0.0000e+00, 2.4732e-02, 0.0000e+00,\n",
      "         7.0980e-03, 0.0000e+00, 1.6308e-02, 0.0000e+00, 1.1993e-02, 0.0000e+00,\n",
      "         3.0525e-03, 4.1716e-03, 1.1671e-02, 0.0000e+00, 0.0000e+00, 1.6625e-02,\n",
      "         0.0000e+00, 8.1553e-05, 4.1380e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         7.1874e-03, 0.0000e+00, 6.9782e-04, 6.7532e-03, 0.0000e+00, 1.2081e-02,\n",
      "         0.0000e+00, 2.9366e-03, 6.4828e-02, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 7.2035e-03, 0.0000e+00, 1.0301e-02, 1.6835e-03,\n",
      "         2.4703e-03, 0.0000e+00, 0.0000e+00, 1.5935e-02, 6.1639e-03, 2.4575e-02,\n",
      "         0.0000e+00, 0.0000e+00, 2.0380e-02, 0.0000e+00, 5.9168e-03, 1.8990e-02,\n",
      "         0.0000e+00, 4.0948e-02, 1.6606e-02, 5.0269e-03, 3.9387e-03, 0.0000e+00,\n",
      "         0.0000e+00, 1.3623e-02, 1.1564e-02, 1.2298e-03, 9.5475e-03, 6.4048e-03,\n",
      "         9.1596e-03, 0.0000e+00, 1.3643e-02, 0.0000e+00, 1.4355e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 1.5290e-02, 0.0000e+00, 1.3582e-02, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 9.9261e-03, 0.0000e+00, 4.1403e-04, 1.8210e-02,\n",
      "         3.3149e-03, 0.0000e+00, 3.1715e-02, 4.4614e-03, 5.3758e-03, 0.0000e+00,\n",
      "         3.3330e-03, 5.0900e-03, 8.3437e-03, 0.0000e+00, 1.2708e-02, 3.1442e-02,\n",
      "         2.5010e-02, 0.0000e+00, 4.8547e-02, 0.0000e+00],\n",
      "        [7.8030e-03, 0.0000e+00, 8.8367e-03, 1.1028e-02, 0.0000e+00, 1.6500e-02,\n",
      "         0.0000e+00, 6.0868e-03, 2.7326e-03, 0.0000e+00, 4.0200e-03, 5.3879e-03,\n",
      "         1.0030e-02, 5.1090e-03, 8.0209e-03, 3.4246e-03, 4.3654e-03, 4.0868e-03,\n",
      "         7.8400e-03, 1.8859e-02, 0.0000e+00, 2.6059e-02, 6.3329e-03, 8.9396e-03,\n",
      "         7.9628e-03, 6.1231e-03, 6.3084e-03, 0.0000e+00, 7.9698e-04, 5.1872e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3300e-03, 0.0000e+00, 2.3333e-03,\n",
      "         0.0000e+00, 1.2482e-02, 0.0000e+00, 1.2749e-03, 0.0000e+00, 7.5244e-03,\n",
      "         0.0000e+00, 4.4921e-03, 6.1712e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         3.6949e-03, 9.8949e-03, 0.0000e+00, 8.0005e-03, 0.0000e+00, 0.0000e+00,\n",
      "         7.3086e-03, 5.8687e-03, 6.7976e-05, 0.0000e+00, 0.0000e+00, 4.9498e-03,\n",
      "         1.1147e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.7242e-04, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.3328e-03,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.5545e-04, 0.0000e+00,\n",
      "         1.9385e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 5.0741e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.3378e-03,\n",
      "         5.9076e-04, 1.0756e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1658e-04,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(dnis.alpha.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "225b0fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_block_mask = alpha_checkpoint.repeat_interleave(dnis.feature_nums.to(dnis.alpha).long(),\n",
    "                                                        dim=0).repeat_interleave(\n",
    "   dnis.embed_dims.to(dnis.alpha).long(), dim=1)\n",
    "                                                \n",
    "#dnis.feature_embeddings.weight.data *= alpha_block_mask\n",
    "#dnis.alpha.data = torch.ones_like(dnis.alpha.data).to(dnis.alpha.data)\n",
    "arr = np.reshape(dnis.feature_embeddings.weight.data.abs().detach().cpu(),(-1))\n",
    "arr = np.sort(arr)\n",
    "embedding_checkpoint = dnis.feature_embeddings.weight.data.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15961cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " threshold: 0.2068343311548233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kongshuming/anaconda3/envs/py37pt17/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fce43c2b924289bf3d4e8da55ef0a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruned: 98%, loss: 0.3857754762718069, auc: 0.7701850390686246\n",
      "4942365\n"
     ]
    }
   ],
   "source": [
    "\n",
    "threshold = arr[int(arr.shape[0]*95/100)]\n",
    "print(f\" threshold: {threshold}\")\n",
    "dnis.feature_embeddings.weight.data = embedding_checkpoint.clone().detach()\n",
    "dnis.feature_embeddings.weight.data[dnis.feature_embeddings.weight.data.abs()<threshold]=0\n",
    "loss, auc = val(dnis,test_dataloader)\n",
    "print(f\"pruned: {98}%, loss: {loss}, auc: {auc}\")\n",
    "print(torch.nonzero(dnis.feature_embeddings.weight.data).size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc32580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdbf70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871c8288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a857f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85993884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2463ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37pt17] *",
   "language": "python",
   "name": "conda-env-py37pt17-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
